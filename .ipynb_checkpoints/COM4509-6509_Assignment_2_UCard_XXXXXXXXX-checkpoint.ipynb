{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Brief \n",
    "\n",
    "## Deadline: Tuesday, December 3, 2019 at 14:00 hrs\n",
    "\n",
    "## Number of marks available: 20\n",
    "\n",
    "## Scope: Sessions 6 to 9\n",
    "\n",
    "## 1. Instructions\n",
    "### How and what to submit\n",
    "\n",
    "A. Submit a Jupyter Notebook named COM4509-6509_Assignment_2_UCard_XXXXXXXXX.ipynb where XXXXXXXXX refers to your UCard number.\n",
    "\n",
    "B. Upload the notebook file to MOLE before the deadline above.\n",
    "\n",
    "C. **NO DATA UPLOAD**: Please do not upload the data files used. We have a copy already. \n",
    "\n",
    "\n",
    "### Assessment Criteria \n",
    "\n",
    "* Being able to manipulate a dataset by generating sythetic data and extracting a particular subset. \n",
    "\n",
    "* Being able to build and train different machine learning models with tunable hyperparameters to optimise given evaluation metric.\n",
    "\n",
    "* Being able to compare different machine learning models and explain interesting results observed. \n",
    "\n",
    "* Being able to follow examples in the lab and write code without the help of starter code.\n",
    "\n",
    "\n",
    "### Late submissions\n",
    "\n",
    "We follow Department's guidelines about late submissions, i.e., a deduction of 5% of the mark each working day the work is late after the deadline. NO late submission will be marked one week after the deadline because we will release a solution by then. Please read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/assessment/late-submission?pli=1&authuser=1). \n",
    "\n",
    "### Use of unfair means \n",
    "\n",
    "**\"Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.\"** (from the MSc Handbook). Please carefully read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/referencing-unfair-means?pli=1&authuser=1) on what constitutes Unfair Means if not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image classification and denoising\n",
    "\n",
    "### The CIFAR-10 dataset\n",
    "In this assignment, we will work on the [**CIFAR-10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html) collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton from the University of Toronto.  This dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. Each image is a 3-channel colour images of 32x32 pixels in size. There are 50000 training images and 10000 test images. \n",
    "\n",
    "\t\t\t\n",
    "### Question 1: Data loading and manipulation (4 marks)\n",
    "\n",
    "1a. **Download** both the training and test data of the CIFAR-10 dataset, e.g., by following the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). You can also download via other ways if you prefer.\n",
    "\n",
    "1b. **Add random noise** to all training and test data to generate noisy dataset, e.g., by `torch.randn()`, with a scaling  factor `scale`, e.g., original image `+ scale * torch.randn()`, and **normalise/standardise** the pixel values to the **original range**, e.g.,  using `np.clip()`. You may choose any `scale` value between 0.2 and 0.5. \n",
    "\n",
    "**Note: Before generating the random noise, you MUST set the random seed to your UCard number XXXXXXXXX for reproducibility, e.g., using `torch.manual_seed()`. This seed needs to be used for all remaining code if there is randomness, for reproducibility.**\n",
    "\n",
    "1c. **Extract a subset** with only two classes: **Cat** and **Dog** and name it starting with **CatDog**.        \n",
    "\n",
    "1d. Show 10 pairs of original and noisy images of cats and 10 pairs of original and noisy images of dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability.\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def make_mask(data, labels = [3,5]):\n",
    "    mask = [True if data[i][1] in labels else False for i in range(len(data))]\n",
    "    mask = torch.tensor(mask)\n",
    "    return YourSampler(mask, data)\n",
    "\n",
    "class YourSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, mask, data_source):\n",
    "        self.mask = mask\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter([i.item() for i in torch.nonzero(self.mask)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5178e3de713b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\"\"\" ================= CatDog =================\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain_cd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mCatDog_train_no_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mCatDog_train_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "class Noise(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        sample += torch.randn(sample.shape) * 0.2\n",
    "        sample = np.clip(sample, -1,1 )\n",
    "        return sample\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "    \n",
    "    \n",
    "noise = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    Noise()])\n",
    "no_noise = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor()])\n",
    "\n",
    "\"\"\" ================= ALL DATA  =================\"\"\"\n",
    "trainset_n = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=noise)\n",
    "trainset_noise = torch.utils.data.DataLoader(trainset_n, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "trainset_no = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=no_noise)\n",
    "trainset_no_noise = torch.utils.data.DataLoader(trainset_no, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset_n = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=noise)\n",
    "testset_noise = torch.utils.data.DataLoader(testset_n, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testset_no = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=no_noise)\n",
    "testset_no_noise = torch.utils.data.DataLoader(testset_no, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" ================= CatDog =================\"\"\"\n",
    "train_cd = make_mask(trainset_n)\n",
    "CatDog_train_no_noise = torch.utils.data.DataLoader(trainset_n, batch_size=BATCH_SIZE, num_workers=2, sampler=train_cd)\n",
    "CatDog_train_noise = torch.utils.data.DataLoader(trainset_no, batch_size=BATCH_SIZE, num_workers=2, sampler=train_cd)\n",
    "\n",
    "test_cd = make_mask(testset_n)\n",
    "CatDog_test_no_noise = torch.utils.data.DataLoader(testset_n, batch_size=BATCH_SIZE, num_workers=2, sampler=test_cd)\n",
    "CatDog_test_noise = torch.utils.data.DataLoader(testset_no, batch_size=BATCH_SIZE, num_workers=2, sampler=test_cd)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def show(label):\n",
    "    num = 0\n",
    "    for (x,y),(i,j) in zip(CatDog_train_noise, CatDog_train_no_noise):\n",
    "        for n,ids in enumerate(y):\n",
    "            if ids == label:\n",
    "                imshow(torchvision.utils.make_grid(x[n]))\n",
    "                imshow(torchvision.utils.make_grid(i[n]))\n",
    "                num += 1\n",
    "            if num >=10:\n",
    "                return\n",
    "            \n",
    "print(\"================ Cats ================\")\n",
    "show(3)\n",
    "\n",
    "print(\"================ Dogs ================\")\n",
    "\n",
    "show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Dimensionality reduction, binary classification, and evaluation (6 marks)\n",
    "\n",
    "This question uses the **CatDog** subset **with no noise added**.\n",
    "\n",
    "#### Training\n",
    "\n",
    "2a. Apply PCA on the training set to reduce the dimensionality. You need to study **at least seven** different values for the reduced dimensionality. **Explain** your choice.\n",
    "\n",
    "2b. Train **eight** Naive Bayes classifiers: one on the original features (raw pixels), and seven on the seven different PCA features in 2a. You will need to decide on what Naive Bayes classifier (Gaussian? Multinomial? etc.) to use and **explain** your choice.\n",
    "\n",
    "#### Testing and evaluation\n",
    "2c. Evalaute the eight Naive Bayes classifiers on the test set in terms of **classification accuracy** and **visualise** their performance using a bar graph.\n",
    "\n",
    "2d. Plot the [ROC Curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) in true positive rates vs false positive rates for the eight Naive Bayes classifiers in **one figure** using eight different line/marker styles clearly labelled. \n",
    "\n",
    "2e. Compute the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) values for the eight Naive Bayes classifiers and visualise using a bar graph.\n",
    "\n",
    "2f. Describe **at least three** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability.\n",
    "\n",
    "def PCA(data, k=200):\n",
    "    # preprocess the data\n",
    "    X = torch.from_numpy(data)\n",
    "    X_mean = torch.mean(X,0)\n",
    "    X = X - X_mean.expand_as(X)\n",
    "\n",
    "    # svd\n",
    "    U,S,V = torch.svd(torch.t(X))\n",
    "    return torch.mm(X,U[:,:k])\n",
    "\n",
    "for \n",
    "\n",
    "imshow(torchvision.utils.make_grid(i[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Noisy data and multiclass classification (6 marks)\n",
    "\n",
    "#### Noisy **CatDog** subset.\n",
    "\n",
    "3a. Repeat 2a, 2b, and 2c on the noisy version of CatDog subset. Show the bar graph and compare it with that in 2c above. \n",
    "\n",
    "#### Multiclass classification using the original CIFAR-10 dataset (all 10 classes)\n",
    "\n",
    "3b. Apply PCA on the training set to reduce the dimensionality. You need to study at least **three** different values for the reduced dimensionality. Explain your choice.\n",
    "\n",
    "3c. Train nine classifers: **four Naive Bayes** classifiers(one on the original features, and three on the three different PCA features in 3b); **four Logistic Regression** classifiers (one on the original features, and three on the three different PCA features in 3b); and one **Convoluational Neural Network** as defined in the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "3d. Evalaute the nine classifiers on the test set. Summarise the **classification accuracy**, **total training time**, and **total test time** using three bar graphs.\n",
    "\n",
    "3e. Show the confusion matrix for these nine classifiers (see Lab 8 - 1.4).\n",
    "\n",
    "3f. Describe **at least three** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Denoising Autoencoder (4 marks)\n",
    "\n",
    "This question uses both the original and noisy CIFAR-10 datasets (all 10 classes).\n",
    "\n",
    "Read about denoising autoencoder at [Wikepedia](https://en.wikipedia.org/wiki/Autoencoder#Denoising_autoencoder_(DAE)) and this [short introduction](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2) or any other sources you like.\n",
    "\n",
    "4a. Modify the autoencoder architecture in Lab 7 so that it takes colour images as input (i.e., 3 input channels). \n",
    "\n",
    "4b. **Training**: feed the **noisy training images** as input to the autoencoder in 4a; use a loss function that computes the reconstruction error between the **output of the autoencoder** and the respective **original images**.\n",
    "\n",
    "4c. **Testing**: evaluate the autoencoder trained in 4b on the test datasets (feed noisy images in and compute reconstruction errors on original clean images. Find the **worstly denoised** 30 images (those with the largest reconstruction errors) in the test set and show them in pairs with the original images (60 images to show in total).\n",
    "\n",
    "4d. Choose at least two hyperparameters to vary. Study **at least three different choices** for each hyperparameter. When varying one hyperparameter, all the other hyperparameters can be fixed. Visualise the performance sensitivity with respect to these hyperparameters.\n",
    "\n",
    "4e. Describe **at least two** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machines",
   "language": "python",
   "name": "machines"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
